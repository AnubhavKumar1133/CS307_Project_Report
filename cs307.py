# -*- coding: utf-8 -*-
"""CS307.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12NGEhakLr9Kk3RzxvsN8rscQ9pLe-WwL
"""

import numpy as np
import pandas as pd
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.metrics import accuracy_score, classification_report, roc_auc_score

# loading the data from sklearn
import sklearn.datasets
breast_cancer_dataset = sklearn.datasets.load_breast_cancer()

# loading the data to a data frame
data_frame = pd.DataFrame(breast_cancer_dataset.data, columns = breast_cancer_dataset.feature_names)

# print the first 5 rows of the dataframe
data_frame.head()

# adding the 'target' column to the data frame
data_frame['label'] = breast_cancer_dataset.target

X = data_frame.drop(columns='label', axis=1)
Y = data_frame['label']

data_frame.size

X.shape[0]

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

# 1. Logistic Regression
from sklearn.linear_model import LogisticRegression

# Data Preprocessing (Scaling)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Training Logistic Regression
log_reg = LogisticRegression(max_iter=200)
log_reg.fit(X_train_scaled, Y_train)

# Evaluate Logistic Regression
y_pred_lr = log_reg.predict(X_test_scaled)
print("Logistic Regression Accuracy:", accuracy_score(Y_test, y_pred_lr))
print(classification_report(Y_test, y_pred_lr))

# Predict for the first 5 rows of the test set
predictions_first_5 = log_reg.predict(X_test_scaled[:5])
print("Predictions for the first 5 rows:", predictions_first_5)
# Actual values for the first 5 rows
actual_first_5 = Y_test[:5].values
print("Actual values for the first 5 rows:", actual_first_5)

# Compare predictions with actual values
for i in range(5):
    print(f"Row {i+1}: Prediction = {predictions_first_5[i]}, Actual = {actual_first_5[i]}")

from sklearn.naive_bayes import GaussianNB

# Naive Bayes does not require scaling
naive_bayes = GaussianNB()
naive_bayes.fit(X_train, Y_train)

# Evaluate Naive Bayes
y_pred_nb = naive_bayes.predict(X_test)
print("Naive Bayes Accuracy:", accuracy_score(Y_test, y_pred_nb))
print(classification_report(Y_test, y_pred_nb))

from sklearn.tree import DecisionTreeClassifier

# Train Decision Tree
decision_tree = DecisionTreeClassifier(random_state= 42)
decision_tree.fit(X_train, Y_train)

# Evaluate Decision Tree
y_pred_dt = decision_tree.predict(X_test)

print("Decision Tree Accuracy:", accuracy_score(Y_test, y_pred_dt))
print(classification_report(Y_test, y_pred_dt))

# importing tensorflow and Keras
import tensorflow as tf
tf.random.set_seed(3)
from tensorflow import keras

# ANN requires scaling
scaler_ann = StandardScaler()
X_train_ann = scaler_ann.fit_transform(X_train)
X_test_ann = scaler_ann.transform(X_test)

# Build ANN Model
model1 = keras.Sequential([
    keras.layers.Flatten(input_shape=(30,)),
    keras.layers.Dense(20, activation='relu'),
    keras.layers.Dense(1, activation='sigmoid')
])

# Compiling the Neural Network
model1.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Training the Neural Network
history = model1.fit(X_train_ann, Y_train, validation_split=0.1, epochs=10)

import matplotlib.pyplot as plt

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])

plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')

plt.legend(['training data', 'validation data'], loc = 'lower right')

# Build ANN Model with two hidden layers
model2 = keras.Sequential([
    keras.layers.Flatten(input_shape=(30,)),
    keras.layers.Dense(20, activation='relu'),
    keras.layers.Dense(10, activation='tanh'),
    keras.layers.Dense(1, activation='sigmoid')
])

# Compiling the Neural Network with two hidden layers
model2.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

# Training the Neural Network
history1 = model2.fit(X_train_ann, Y_train, validation_split=0.1, epochs=10)

import matplotlib.pyplot as plt

  plt.plot(history1.history['accuracy'])
  plt.plot(history1.history['val_accuracy'])

  plt.title('model accuracy')
  plt.ylabel('accuracy')
  plt.xlabel('epoch')

  plt.legend(['training data', 'validation data'], loc = 'lower right')

test_loss1, test_accuracy1 = model1.evaluate(X_test_ann, Y_test)
print(f"Model1 Test Accuracy: {test_accuracy1}")

test_loss2, test_accuracy2 = model2.evaluate(X_test_ann, Y_test)
print(f"Model2 Test Accuracy: {test_accuracy2}")

from sklearn.feature_selection import RFE
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
import numpy as np

# Scale the features
scaler = StandardScaler()
X_train_scaled1 = scaler.fit_transform(X_train)
X_test_scaled1 = scaler.transform(X_test)

# Initialize Logistic Regression model
log_reg1 = LogisticRegression(max_iter=1000, random_state=42)

# Recursive Feature Elimination (RFE)
rfe = RFE(log_reg1, n_features_to_select=8)  # Select top 8 features (you can adjust this number)
rfe.fit(X_train_scaled1, Y_train)

# Transform the data to keep only the selected features
X_train_selected = X_train.iloc[:, rfe.support_]
X_test_selected = X_test.iloc[:, rfe.support_]

# Display selected feature names
selected_feature_names = X.columns[rfe.support_]
print("Selected Features by RFE:\n", selected_feature_names)

# Train Logistic Regression on the selected features
log_reg1.fit(X_train_selected, Y_train)

# Evaluate the Logistic Regression model
y_pred_lr = log_reg1.predict(X_test_selected)
print("Logistic Regression Accuracy on RFE-selected features:", accuracy_score(Y_test, y_pred_lr))
print(classification_report(Y_test, y_pred_lr))

scaler = StandardScaler()
X_train_scaled2 = scaler.fit_transform(X_train_selected)
X_test_scaled2 = scaler.transform(X_test_selected)

# Build ANN model
model3 = keras.Sequential([
    keras.layers.Flatten(input_shape=(X_train_scaled2.shape[1],)),
    keras.layers.Dense(20, activation='relu'),
    keras.layers.Dense(10, activation='relu'),
    keras.layers.Dense(1, activation='sigmoid')
])

# Compile the model
model3.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
history = model3.fit(X_train_scaled2, Y_train, epochs=50, validation_split=0.1, verbose=1)

# Evaluate on the test set
loss, accuracy = model3.evaluate(X_test_scaled2, Y_test, verbose=0)
print(f"Test Accuracy: {accuracy:.4f}")

# Predictions
y_pred_ann = (model3.predict(X_test_scaled2) > 0.5).astype(int)
print("Classification Report:\n", classification_report(Y_test, y_pred_ann.flatten()))

from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc
import matplotlib.pyplot as plt
import seaborn as sns

# Model names and their predictions
models = {
    "Logistic Regression": (y_pred_lr, log_reg.predict_proba(X_test_scaled)[:, 1]),
    "Naive Bayes": (y_pred_nb, naive_bayes.predict_proba(X_test)[:, 1]),
    "Decision Tree": (y_pred_dt, decision_tree.predict_proba(X_test)[:, 1]),
    "ANN Model 1": (model1.predict(X_test_ann) > 0.5, model1.predict(X_test_ann).flatten()),
    "ANN Model 2": (model2.predict(X_test_ann) > 0.5, model2.predict(X_test_ann).flatten()),
    "ANN Model 3 (RFE-selected)": (y_pred_ann.flatten(), model3.predict(X_test_scaled2).flatten()),
}

# Confusion Matrices
plt.figure(figsize=(15, 10))
for i, (model_name, (y_pred, _)) in enumerate(models.items()):
    cm = confusion_matrix(Y_test, y_pred.astype(int))
    plt.subplot(3, 2, i + 1)
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False)
    plt.title(f"Confusion Matrix: {model_name}")
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
plt.tight_layout()
plt.show()

# Accuracy Bar Plot
accuracies = [accuracy_score(Y_test, y_pred.astype(int)) for y_pred, _ in models.values()]
plt.figure(figsize=(10, 6))
sns.barplot(x=list(models.keys()), y=accuracies, palette="viridis")
plt.title("Model Accuracy Comparison")
plt.ylabel("Accuracy")
plt.xticks(rotation=45, ha="right")
plt.ylim(0.8, 1)
plt.show()

# ROC Curves
plt.figure(figsize=(10, 8))
for model_name, (_, y_proba) in models.items():
    fpr, tpr, _ = roc_curve(Y_test, y_proba)
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, label=f"{model_name} (AUC = {roc_auc:.2f})")
plt.plot([0, 1], [0, 1], "k--", label="Random Guess (AUC = 0.50)")
plt.title("ROC Curve Comparison")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend(loc="lower right")
plt.grid()
plt.show()

# Precision, Recall, and F1-Score Table
from sklearn.metrics import precision_recall_fscore_support

metrics = []
for model_name, (y_pred, _) in models.items():
    precision, recall, f1, _ = precision_recall_fscore_support(Y_test, y_pred.astype(int), average="binary")
    metrics.append({"Model": model_name, "Precision": precision, "Recall": recall, "F1-Score": f1})

metrics_df = pd.DataFrame(metrics)
print(metrics_df)

# Heatmap for Precision, Recall, and F1-Score
plt.figure(figsize=(10, 5))
sns.heatmap(metrics_df.set_index("Model"), annot=True, cmap="coolwarm", cbar=True, fmt=".2f")
plt.title("Precision, Recall, and F1-Score Comparison")
plt.show()